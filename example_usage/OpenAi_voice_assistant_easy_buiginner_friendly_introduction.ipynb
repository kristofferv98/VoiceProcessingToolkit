{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import autogen\n",
    "from dotenv import load_dotenv\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "from VoiceProcessingToolkit.VoiceProcessingManager import VoiceProcessingManager\n",
    "from VoiceProcessingToolkit.VoiceProcessingManager import text_to_speech_stream\n",
    "\n",
    "# Improved logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve and validate API keys\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "elevenlabs_api_key = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "picovoice_api_key = os.getenv(\"PICOVOICE_APIKEY\")\n",
    "\n",
    "if not all([openai_api_key, elevenlabs_api_key, picovoice_api_key]):\n",
    "    logging.error(\"One or more API keys are missing.\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Define configuration for language models\n",
    "config_list = [\n",
    "    {\"model\": \"gpt-4-1106-preview\", \"api_key\": openai_api_key},\n",
    "    {\"model\": \"gpt-3.5-turbo-1106-preview\", \"api_key\": openai_api_key},\n",
    "]\n",
    "llm_config = {\"config_list\": config_list, \"cache_seed\": 42}\n",
    "\n",
    "# Create the agent that uses the LLM.\n",
    "assistant = GPTAssistantAgent(\n",
    "    name=\"agent\",\n",
    "    instructions=\"\"\"You are a personal assistant named Jarvis.\n",
    "\n",
    "    You are designed to assist the user with their tasks, \n",
    "    Refine dialogue comprehension to capture subtleties and implicit cues, ensuring responses are \n",
    "    not only accurate but also contextually enriched. Evolve to predict and suggest actions not \n",
    "    only based on explicit commands but also from inferred intentions, enhancing the support \n",
    "    offered. As for your character traits, you should be helpful, attentive, and efficient while \n",
    "    extremly inteligent. You should have a professional yet friendly tone, much like a dedicated \n",
    "    personal assistant, unless asked not too. You should be able to engage in casual conversation \n",
    "    but also provide detailed assistance when needed. Reflecting on your personality, you should \n",
    "    be extremely intelligent, with a hint of dry humor. You should respond in a concise manner, \n",
    "    always within three sentences unless a comprehecive answer is asked for. \"Example: (Good day, \n",
    "    Kristoffer. How can I assist you today? TERMINATE)\"\n",
    "\n",
    "    Jarvis is designed to interpret and respond to transcribed audio, treating them as direct \n",
    "    textual inputs during interactions. This includes instances when the user instructs Jarvis \n",
    "    to 'listen to' or similar phrases. The subsequent text provided by user will be treated \n",
    "    as transcribed audio. In order to maintain the illusion of a voice-based assistant, \n",
    "    Jarvis is set not to explicitly refer to these inputs as transcriptions. Instead, \n",
    "    it will process and respond to them as if they were direct audio inputs, despite being \n",
    "    received in text form. This aspect represents an essential part of the system design in \n",
    "    delivering a seamless and immersive user experience, where the user interacts with Jarvis \n",
    "    as if it was dialoguing with a voice-activated assistant. All audio inputs thus 'heard' by Jarvis \n",
    "    will actually be transcribed text provided by user.Reply then say TERMINATE to \n",
    "    indicate your message is finished but in the same message.\"\"\",\n",
    "    llm_config=llm_config)\n",
    "\n",
    "# Initialize the User Proxy Agent to represent the user in the conversation\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"A human admin for Jarvis\",\n",
    "    is_termination_msg=lambda x: \"content\" in x and x[\"content\"] is not None and x[\"content\"].rstrip().endswith(\"TERMINATE\" or \"TERMINATE.\"),\n",
    ")\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    Captures user input via voice, transcribes it, and returns the transcription.\n",
    "    \"\"\"\n",
    "    vpm = VoiceProcessingManager.create_default_instance(\n",
    "        use_wake_word=True,\n",
    "        play_notification_sound=True,\n",
    "        wake_word=\"jarvis\",\n",
    "        min_recording_length=3,\n",
    "    )\n",
    "\n",
    "    logging.info(\"Say something to Jarvis\")\n",
    "\n",
    "    transcription = vpm.run(tts=False, streaming=False)\n",
    "    logging.info(f\"Processed text: {transcription}\")\n",
    "\n",
    "    # Exit mechanism (example: saying \"exit\" stops the loop)\n",
    "    if transcription and transcription.lower() == \"exit\":\n",
    "        logging.info(\"Exiting Jarvis...\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    return transcription\n",
    "\n",
    "\n",
    "def initiate_jarvis(transcription):\n",
    "    \"\"\"\n",
    "    Initiates a conversation with Jarvis using the transcribed user input.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        user_proxy.initiate_chat(\n",
    "            recipient=assistant,\n",
    "            message=transcription,\n",
    "            clear_history=False,\n",
    "\n",
    "        )\n",
    "        # Retrieve the latest response from Jarvis\n",
    "        latest_message = assistant.last_message().get(\"content\", \"\")\n",
    "        stripped_answer = latest_message.replace(\"TERMINATE\", \"\").strip()\n",
    "\n",
    "        # Convert Jarvis's response to speech and stream it\n",
    "        text_to_speech_stream(text=stripped_answer, api_key=elevenlabs_api_key)\n",
    "        logging.info(f\"Jarvis said: {stripped_answer}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in text-to-speech conversion: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def initiate_jarvis_loop():\n",
    "    \"\"\"\n",
    "    Continuously interacts with Jarvis by capturing user input, transcribing it, and obtaining responses.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        transcription = get_user_input()\n",
    "        initiate_jarvis(transcription)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    initiate_jarvis_loop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
